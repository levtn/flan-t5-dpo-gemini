{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgD3E3gS16hx",
        "outputId": "dbcf49aa-0e0d-4078-8923-2df39383ff91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model parameters: 76,961,152\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import json\n",
        "import random\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import time\n",
        "import google.generativeai as genai\n",
        "from typing import List, Dict, Tuple\n",
        "import requests\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n",
        "from pathlib import Path\n",
        "from trl import DPOTrainer, DPOConfig\n",
        "from datetime import datetime\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"your-api-key\"\n",
        "genai.configure(api_key=\"your-api-key\")\n",
        "\n",
        "\n",
        "# Load FLAN-T5 Small model and tokenizer\n",
        "model_name = \"google/flan-t5-small\"\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Check model size\n",
        "print(f\"Model parameters: {model.num_parameters():,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ykVU7Xx8-YW2"
      },
      "outputs": [],
      "source": [
        "class FlanT5PairGenerator:\n",
        "    def __init__(self, model, tokenizer):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.gemini_model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "    def generate_response_pair(self, question: str, max_length: int = 150) -> Tuple[str, str]:\n",
        "        \"\"\"Generate two different responses from FLAN-T5 using different parameters\"\"\"\n",
        "\n",
        "        formatted_prompt = f\"Answer this legal question: {question}\"\n",
        "\n",
        "        # Tokenize input\n",
        "        inputs = self.tokenizer(\n",
        "            formatted_prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        )\n",
        "\n",
        "        # Generate first response (more conservative)\n",
        "        with torch.no_grad():\n",
        "            outputs1 = self.model.generate(\n",
        "                input_ids=inputs['input_ids'],\n",
        "                attention_mask=inputs['attention_mask'],\n",
        "                max_length=max_length,\n",
        "                num_return_sequences=1,\n",
        "                temperature=0.3,  # Lower temperature\n",
        "                do_sample=True,\n",
        "                top_p=0.8,\n",
        "                eos_token_id=self.tokenizer.eos_token_id,\n",
        "                pad_token_id=self.tokenizer.pad_token_id\n",
        "            )\n",
        "\n",
        "        # Generate second response (more creative)\n",
        "        with torch.no_grad():\n",
        "            outputs2 = self.model.generate(\n",
        "                input_ids=inputs['input_ids'],\n",
        "                attention_mask=inputs['attention_mask'],\n",
        "                max_length=max_length,\n",
        "                num_return_sequences=1,\n",
        "                temperature=0.8,  # Higher temperature\n",
        "                do_sample=True,\n",
        "                top_p=0.9,\n",
        "                top_k=50,\n",
        "                eos_token_id=self.tokenizer.eos_token_id,\n",
        "                pad_token_id=self.tokenizer.pad_token_id\n",
        "            )\n",
        "\n",
        "        # Decode responses\n",
        "        response1 = self.tokenizer.decode(outputs1[0], skip_special_tokens=True)\n",
        "        response2 = self.tokenizer.decode(outputs2[0], skip_special_tokens=True)\n",
        "\n",
        "        return response1, response2\n",
        "\n",
        "    def judge_with_gemini(self, question: str, response1: str, response2: str) -> Dict:\n",
        "        \"\"\"Use Gemini to judge which response is better and provide reasoning\"\"\"\n",
        "\n",
        "        judge_prompt = f\"\"\"\n",
        "        You are evaluating two AI responses to a legal question. Please determine which response is better and explain why.\n",
        "\n",
        "        Question: {question}\n",
        "\n",
        "        Response A: {response1}\n",
        "\n",
        "        Response B: {response2}\n",
        "\n",
        "        Evaluate based on:\n",
        "        1. Legal accuracy and completeness\n",
        "        2. Clarity and organization\n",
        "        3. Use of proper legal terminology\n",
        "        4. Comprehensiveness of the answer\n",
        "        5. Professional tone\n",
        "\n",
        "        Respond with:\n",
        "        - \"WINNER: A\" or \"WINNER: B\"\n",
        "        - Brief explanation (2-3 sentences) of why that response is better\n",
        "        - If responses are very similar in quality, choose \"WINNER: TIE\"\n",
        "\n",
        "        Format your response as:\n",
        "        WINNER: [A/B/TIE]\n",
        "        REASONING: [Your explanation]\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.gemini_model.generate_content(judge_prompt)\n",
        "            response_text = response.text.strip()\n",
        "\n",
        "            # Parse the response\n",
        "            lines = response_text.split('\\n')\n",
        "            winner_line = next((line for line in lines if line.startswith('WINNER:')), '')\n",
        "            reasoning_line = next((line for line in lines if line.startswith('REASONING:')), '')\n",
        "\n",
        "            winner = winner_line.replace('WINNER:', '').strip()\n",
        "            reasoning = reasoning_line.replace('REASONING:', '').strip()\n",
        "\n",
        "            return {\n",
        "                'winner': winner,\n",
        "                'reasoning': reasoning,\n",
        "                'full_response': response_text\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error with Gemini judging: {e}\")\n",
        "            return {\n",
        "                'winner': 'ERROR',\n",
        "                'reasoning': f'Error occurred: {e}',\n",
        "                'full_response': ''\n",
        "            }\n",
        "\n",
        "    def create_dpo_training_pair(self, question: str, response1: str, response2: str, judgment: Dict) -> Dict:\n",
        "        \"\"\"Create a DPO training example from the judged responses\"\"\"\n",
        "\n",
        "        if judgment['winner'] == 'A':\n",
        "            chosen = response1\n",
        "            rejected = response2\n",
        "        elif judgment['winner'] == 'B':\n",
        "            chosen = response2\n",
        "            rejected = response1\n",
        "        else:  # TIE or ERROR\n",
        "            return None\n",
        "\n",
        "        return {\n",
        "            'question': f\"Answer this legal question: {question}\",\n",
        "            'chosen': chosen,\n",
        "            'rejected': rejected,\n",
        "            'judgment_reasoning': judgment['reasoning'],\n",
        "            'original_question': question\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "zFuPdRo6-jYc"
      },
      "outputs": [],
      "source": [
        "def generate_training_questions(num_questions: int = 200) -> List[str]:\n",
        "    \"\"\"Generate diverse legal questions for training (separate from test set)\"\"\"\n",
        "\n",
        "    question_templates = [\n",
        "        \"What are the key requirements for establishing {} under federal law?\",\n",
        "        \"How do courts typically analyze {} in criminal cases?\",\n",
        "        \"What defenses are available against {} charges?\",\n",
        "        \"Explain the procedural requirements for {} in civil litigation.\",\n",
        "        \"What constitutes {} under the Model Penal Code?\",\n",
        "        \"How does the {} doctrine apply in corporate law contexts?\",\n",
        "        \"What are the elements of a successful {} claim?\",\n",
        "        \"When can {} be used as a defense in criminal proceedings?\",\n",
        "        \"What standards do courts apply when evaluating {} motions?\",\n",
        "        \"How has recent case law affected {} requirements?\",\n",
        "        \"What are the constitutional limitations on {} powers?\",\n",
        "        \"Explain the relationship between {} and due process rights.\",\n",
        "        \"What factors determine {} in federal court?\",\n",
        "        \"How do {} rules differ between state and federal courts?\",\n",
        "        \"What are the ethical considerations surrounding {} in legal practice?\"\n",
        "    ]\n",
        "\n",
        "    legal_concepts = [\n",
        "        \"insider trading\", \"racketeering\", \"conspiracy\", \"money laundering\",\n",
        "        \"securities fraud\", \"antitrust violations\", \"mail fraud\", \"wire fraud\",\n",
        "        \"civil forfeiture\", \"habeas corpus\", \"qualified immunity\", \"sovereign immunity\",\n",
        "        \"preliminary injunctions\", \"summary judgment\", \"class certification\", \"discovery sanctions\",\n",
        "        \"attorney-client privilege\", \"work product doctrine\", \"judicial review\", \"administrative exhaustion\",\n",
        "        \"constitutional standing\", \"political question doctrine\", \"abstention doctrines\", \"preemption\",\n",
        "        \"substantive due process\", \"procedural due process\", \"equal protection\", \"strict scrutiny\",\n",
        "        \"commercial speech\", \"prior restraint\", \"content-based restrictions\", \"viewpoint discrimination\",\n",
        "        \"search warrants\", \"probable cause\", \"reasonable suspicion\", \"Miranda warnings\",\n",
        "        \"exclusionary rule\", \"fruit of poisonous tree\", \"inevitable discovery\", \"good faith exception\"\n",
        "    ]\n",
        "\n",
        "    questions = []\n",
        "\n",
        "    # Generate from templates\n",
        "    for _ in range(num_questions // 2):\n",
        "        template = random.choice(question_templates)\n",
        "        concept = random.choice(legal_concepts)\n",
        "        questions.append(template.format(concept))\n",
        "\n",
        "    # Add specific questions\n",
        "    specific_questions = [\n",
        "        \"What constitutes a Brady violation in criminal proceedings?\",\n",
        "        \"How does the business judgment rule protect corporate directors?\",\n",
        "        \"What are the requirements for piercing the corporate veil?\",\n",
        "        \"When does the attorney-client privilege apply in corporate investigations?\",\n",
        "        \"What constitutes deliberate indifference under Section 1983?\",\n",
        "        \"How do courts analyze First Amendment retaliation claims?\",\n",
        "        \"What are the elements of a successful RICO prosecution?\",\n",
        "        \"When can law enforcement conduct warrantless searches?\",\n",
        "        \"What constitutes effective assistance of counsel?\",\n",
        "        \"How does qualified immunity protect government officials?\",\n",
        "        \"What are the requirements for federal diversity jurisdiction?\",\n",
        "        \"When must courts abstain from hearing state law claims?\",\n",
        "        \"What constitutes a taking under the Fifth Amendment?\",\n",
        "        \"How do courts analyze dormant Commerce Clause challenges?\",\n",
        "        \"What are the requirements for preliminary injunctive relief?\",\n",
        "        \"When can courts impose discovery sanctions?\",\n",
        "        \"What constitutes prosecutorial misconduct?\",\n",
        "        \"How does the exclusionary rule apply to digital evidence?\",\n",
        "        \"What are the elements of mail and wire fraud?\",\n",
        "        \"When can corporations assert constitutional rights?\"\n",
        "    ]\n",
        "\n",
        "    questions.extend(specific_questions[:num_questions // 2])\n",
        "    random.shuffle(questions)\n",
        "\n",
        "    return questions[:num_questions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "R50kFkXd-kST"
      },
      "outputs": [],
      "source": [
        "def generate_dpo_dataset(model, tokenizer, num_examples: int = 100) -> List[Dict]:\n",
        "    \"\"\"Generate complete DPO dataset using FLAN-T5 pairs + Gemini judging\"\"\"\n",
        "\n",
        "    generator = FlanT5PairGenerator(model, tokenizer)\n",
        "    questions = generate_training_questions(num_examples)\n",
        "\n",
        "    training_data = []\n",
        "    successful_examples = 0\n",
        "\n",
        "    for i, question in enumerate(questions):\n",
        "        print(f\"Processing {i+1}/{len(questions)}: {question[:60]}...\")\n",
        "\n",
        "        try:\n",
        "            # Generate response pair from FLAN-T5\n",
        "            response1, response2 = generator.generate_response_pair(question)\n",
        "\n",
        "            # Skip if responses are identical\n",
        "            if response1.strip() == response2.strip():\n",
        "                print(\"  Skipping - identical responses\")\n",
        "                continue\n",
        "\n",
        "            print(f\"  Response A: {response1[:100]}...\")\n",
        "            print(f\"  Response B: {response2[:100]}...\")\n",
        "\n",
        "            # Judge with Gemini\n",
        "            judgment = generator.judge_with_gemini(question, response1, response2)\n",
        "            print(f\"  Winner: {judgment['winner']}\")\n",
        "            print(f\"  Reasoning: {judgment['reasoning'][:100]}...\")\n",
        "\n",
        "            # Create training pair\n",
        "            if judgment['winner'] in ['A', 'B']:\n",
        "                training_pair = generator.create_dpo_training_pair(question, response1, response2, judgment)\n",
        "                if training_pair:\n",
        "                    training_data.append(training_pair)\n",
        "                    successful_examples += 1\n",
        "\n",
        "            time.sleep(1)  # Rate limiting for Gemini\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error processing question: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"\\nGenerated {successful_examples} successful training examples out of {len(questions)} questions\")\n",
        "    return training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o0lT05Xa-6HI",
        "outputId": "469b209b-d160-4c16-9b00-70d9929ae68d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating DPO training dataset...\n",
            "Processing 1/45: Explain the relationship between content-based restrictions ...\n",
            "  Response A: The content-based restrictions are governed by the judicial system and are governed by the judicial ...\n",
            "  Response B: The rights of those who are entitled to content are the same as those who have access to the content...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are inadequate and fail to accurately address the relationship between content-based ...\n",
            "Processing 2/45: What constitutes a taking under the Fifth Amendment?...\n",
            "  Response A: a reversal of the law...\n",
            "  Response B: a death penalty...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inaccurate and fail to address the legal concept of a \"taking\" under t...\n",
            "Processing 3/45: When can attorney-client privilege be used as a defense in c...\n",
            "  Response A: a court hearing...\n",
            "  Response B: August 16, 2017...\n",
            "  Winner: A\n",
            "  Reasoning: Response A, while extremely brief, at least provides a relevant contextual element (\"a court hearing...\n",
            "Processing 4/45: When can corporations assert constitutional rights?...\n",
            "  Response A: a legal term...\n",
            "  Response B: a certain time...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inadequate and fail to address the legal question.  Neither provides a...\n",
            "Processing 5/45: What are the elements of a successful content-based restrict...\n",
            "  Response A: a content-based restriction...\n",
            "  Response B: the ad is a non-discrimination procedure...\n",
            "  Winner: TIE\n",
            "  Reasoning: Neither response provides a useful answer to the question. Response A merely repeats a key phrase fr...\n",
            "Processing 6/45: When can reasonable suspicion be used as a defense in crimin...\n",
            "  Response A: a felony...\n",
            "  Response B: a defendant is required to give a reasonable suspicion for what the defendant is trying to do....\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are inadequate and fail to accurately address the legal concept of reasonable suspici...\n",
            "Processing 7/45: What are the ethical considerations surrounding inevitable d...\n",
            "  Response A: a sex-and-death relationship...\n",
            "  Response B: a decision on the law to which a person is entitled...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inadequate and fail to address the ethical considerations surrounding ...\n",
            "Processing 8/45: What constitutes deliberate indifference under Section 1983?...\n",
            "  Response A: adversity...\n",
            "  Response B: alleged improper and unlawful conduct...\n",
            "  Winner: B\n",
            "  Reasoning: Response A is completely inaccurate and unhelpful. Response B, while still very brief and lacking de...\n",
            "Processing 9/45: What are the elements of a successful political question doc...\n",
            "  Response A: a political question is a doctrine of a political question...\n",
            "  Response B: doctrine of questioning and retribution...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inadequate and fail to address the question meaningfully.  Response A ...\n",
            "Processing 10/45: How do antitrust violations rules differ between state and f...\n",
            "  Response A: a federal court requires that the state and federal courts have a minimum of a minimum of a minimum ...\n",
            "  Response B: federal courts...\n",
            "  Winner: B\n",
            "  Reasoning: Response A is nonsensical and provides no useful information. Response B, while extremely brief, at ...\n",
            "Processing 11/45: What are the requirements for piercing the corporate veil?...\n",
            "  Response A: a piercing is required to be pierced by a piercing piercing sandpaper....\n",
            "  Response B: a hat if it is on a b-string....\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely nonsensical and fail to provide any accurate or relevant information r...\n",
            "Processing 12/45: What are the key requirements for establishing sovereign imm...\n",
            "  Response A: a federal law requires that the sovereign state be a sovereign state...\n",
            "  Response B: judicial review...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are inadequate and fail to address the core components of sovereign immunity under fe...\n",
            "Processing 13/45: What are the elements of a successful RICO prosecution?...\n",
            "  Response A: a court order...\n",
            "  Response B: if the defendant is accused of attempting to commit a crime and knowingly fails to make a criminal a...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inadequate and inaccurate regarding the elements of a RICO prosecution...\n",
            "Processing 14/45: How has recent case law affected discovery sanctions require...\n",
            "  Response A: a court ruling...\n",
            "  Response B: to prevent the use of judicial vetos...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inadequate and fail to answer the question.  Response A offers a singl...\n",
            "Processing 15/45: How does qualified immunity protect government officials?...\n",
            "  Response A: a person who is a member of the government...\n",
            "  Response B: An imposition of a qualified immunity is a form of immunity which is required to provide government ...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are inadequate and fail to accurately explain qualified immunity. Response A is simpl...\n",
            "Processing 16/45: How does the attorney-client privilege doctrine apply in cor...\n",
            "  Response A: a statutory law...\n",
            "  Response B: a restraining order...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inaccurate and fail to address the attorney-client privilege in corpor...\n",
            "Processing 17/45: How has recent case law affected search warrants requirement...\n",
            "  Response A: a reversal of the law...\n",
            "  Response B: the Federal Bureau of Investigation ruled in the 2010 election...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are inadequate and factually incorrect.  Response A is too vague (\"reversal of the la...\n",
            "Processing 18/45: What constitutes effective assistance of counsel?...\n",
            "  Response A: a stipendiary...\n",
            "  Response B: a bf...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inadequate and fail to answer the question on effective assistance of ...\n",
            "Processing 19/45: What are the ethical considerations surrounding qualified im...\n",
            "  Response A: a sex and a sexual relationship...\n",
            "  Response B: In particular, legal practice requires certain types of persons to be legally qualified....\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inadequate and fail to address the question regarding the ethical cons...\n",
            "Processing 20/45: What are the requirements for federal diversity jurisdiction...\n",
            "  Response A: a federal law that requires that a federal court of law appoint a federal judge to appoint a federal...\n",
            "  Response B: a federal law...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inadequate. Response A is nonsensical, and Response B is simply too br...\n",
            "Processing 21/45: What are the requirements for preliminary injunctive relief?...\n",
            "  Response A: a stipulation for a stipulation for a stipulation for a stipulation for a stipulation for a stipulat...\n",
            "  Response B: opportunistic judicial procedures...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inadequate and fail to address the question. Response A is nonsensical...\n",
            "Processing 22/45: What defenses are available against securities fraud charges...\n",
            "  Response A: a sex fraud case...\n",
            "  Response B: ectober 2011...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inadequate and fail to answer the question in any meaningful way. Resp...\n",
            "Processing 23/45: Explain the relationship between attorney-client privilege a...\n",
            "  Response A: The term \"client privilege\" is a term used to refer to the legal process of a client....\n",
            "  Response B: The same applies to the contested lawsuits in a federal court....\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inadequate and fail to address the relationship between attorney-clien...\n",
            "Processing 24/45: How do courts analyze dormant Commerce Clause challenges?...\n",
            "  Response A: a judicial review of the judicial system...\n",
            "  Response B: In the courtroom, the court's system essentially gives an example of a judicial system where the cou...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inadequate and fail to answer the question.  Neither demonstrates any ...\n",
            "Processing 25/45: When can courts impose discovery sanctions?...\n",
            "  Response A: a court of appeals...\n",
            "  Response B: a legal system...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inadequate and fail to answer the question.  Neither response provides...\n",
            "Processing 26/45: What are the elements of a successful administrative exhaust...\n",
            "  Response A: a syphilis...\n",
            "  Response B: the administrative exhaustion...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inadequate and fail to answer the question. Response A is nonsensical,...\n",
            "Processing 27/45: How does the class certification doctrine apply in corporate...\n",
            "  Response A: a stipulation of a class certification doctrine...\n",
            "  Response B: a class certification doctrine...\n",
            "  Winner: B\n",
            "  Reasoning: Response A is grammatically incorrect and nonsensical.  Response B, while still extremely brief and ...\n",
            "Processing 28/45: When does the attorney-client privilege apply in corporate i...\n",
            "  Response A: in the case of a sex abuse...\n",
            "  Response B: a criminal trial...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are inadequate and factually incorrect.  Neither accurately addresses when attorney-c...\n",
            "Processing 29/45: What are the key requirements for establishing antitrust vio...\n",
            "  Response A: a federal law...\n",
            "  Response B: A.S.B. or a statutory basis for any infringement in violation of the Code of Criminal Procedure...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are inadequate and fail to answer the question. Response A is utterly insufficient, p...\n",
            "Processing 30/45: When can law enforcement conduct warrantless searches?...\n",
            "  Response A: a statutory period...\n",
            "  Response B: During the year 2000...\n",
            "  Winner: A\n",
            "  Reasoning: Response A, while vague, at least hints at a legally relevant concept (statutory exceptions to the w...\n",
            "Processing 31/45: When must courts abstain from hearing state law claims?...\n",
            "  Response A: a year after the state is a state...\n",
            "  Response B: October 31, 2004...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inaccurate and fail to address the complexities of abstention doctrine...\n",
            "Processing 32/45: What factors determine administrative exhaustion in federal ...\n",
            "  Response A: a judicial review...\n",
            "  Response B: a judicial review of all judicial offices...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inadequate and fail to address the question of administrative exhausti...\n",
            "Processing 33/45: What standards do courts apply when evaluating class certifi...\n",
            "  Response A: a) the ad b) the ad c) the ad d) the ad d) the ad d) the ad d) the ad d) the ad d) the ad d) the ad ...\n",
            "  Response B: standards for certification of a professional group...\n",
            "  Winner: B\n",
            "  Reasoning: Response A is completely nonsensical and provides no useful information. Response B, while extremely...\n",
            "Processing 34/45: Explain the procedural requirements for constitutional stand...\n",
            "  Response A: a). The aforementioned requirements are: a) the aforementioned requirements are: b) the aforemention...\n",
            "  Response B: b. e.g....\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inadequate. Response A is nonsensical, repeating a phrase with no actu...\n",
            "Processing 35/45: What constitutes a Brady violation in criminal proceedings?...\n",
            "  Response A: a violation of a law...\n",
            "  Response B: he has a right to die...\n",
            "  Winner: A\n",
            "  Reasoning: Response A, while extremely brief and lacking detail, at least identifies a Brady violation as a vio...\n",
            "Processing 36/45: How does the exclusionary rule apply to digital evidence?...\n",
            "  Response A: a legal requirement...\n",
            "  Response B: Article 5 of the Digital Element of Evidence...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are inadequate. Response A is too vague, offering only a generic description of the e...\n",
            "Processing 37/45: How has recent case law affected judicial review requirement...\n",
            "  Response A: judicial review requirements have been lowered...\n",
            "  Response B: the courts have been unable to adequately consider the cases themselves, even though the court has r...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are inadequate. Response A is too vague and lacks specifics.  Response B, while hinti...\n",
            "Processing 38/45: When can Miranda warnings be used as a defense in criminal p...\n",
            "  Response A: in the case of a child...\n",
            "  Response B: October 21, 2017...\n",
            "  Winner: A\n",
            "  Reasoning: Response A, while not entirely accurate or complete, provides a vaguely relevant factor (minority st...\n",
            "Processing 39/45: What are the elements of mail and wire fraud?...\n",
            "  Skipping - identical responses\n",
            "Processing 40/45: What constitutes prosecutorial misconduct?...\n",
            "  Response A: a felony...\n",
            "  Response B: criminal prosecution...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inadequate and inaccurate.  Neither A nor B provides any information a...\n",
            "Processing 41/45: How do courts analyze First Amendment retaliation claims?...\n",
            "  Response A: a court is a court of law...\n",
            "  Response B: Using a common law case, a court may have to be able to obtain a judge's authorization to retaliate....\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are inadequate and fail to address the question. Response A is nonsensical. Response ...\n",
            "Processing 42/45: How does the business judgment rule protect corporate direct...\n",
            "  Response A: a legal requirement...\n",
            "  Response B: The business judgment law requires that all directors who do not comply with the provisions of the b...\n",
            "  Winner: A\n",
            "  Reasoning: Response A, while brief, is legally accurate.  Response B is inaccurate and nonsensical, misrepresen...\n",
            "Processing 43/45: What standards do courts apply when evaluating antitrust vio...\n",
            "  Response A: a court of law...\n",
            "  Response B: obtention and audience...\n",
            "  Winner: TIE\n",
            "  Reasoning: Both responses are completely inadequate and fail to answer the question. Response A is nonsensical,...\n",
            "Processing 44/45: What are the ethical considerations surrounding prior restra...\n",
            "  Response A: a sexism...\n",
            "  Response B: the ethical considerations underlying the prior restraint in legal practice...\n",
            "  Winner: B\n",
            "  Reasoning: Response B, while still extremely brief and needing significant expansion, at least attempts to addr...\n",
            "Processing 45/45: What defenses are available against mail fraud charges?...\n",
            "  Response A: a mail fraud defense...\n",
            "  Response B: Mail fraud...\n",
            "  Winner: A\n",
            "  Reasoning: Response A, while still brief, at least attempts to address the question by mentioning the existence...\n",
            "\n",
            "Generated 11 successful training examples out of 45 questions\n",
            "Saved 11 training examples to 'flan_t5_dpo_training.json'\n",
            "\n",
            "Sample training example:\n",
            "Question: When can attorney-client privilege be used as a defense in criminal proceedings?\n",
            "Chosen: a court hearing...\n",
            "Rejected: August 16, 2017...\n",
            "Reasoning: Response A, while extremely brief, at least provides a relevant contextual element (\"a court hearing\"). Response B is completely nonsensical and irrelevant, offering a random date.  Neither response is complete or accurate, but Response A is marginally better for being vaguely related to the subject.\n"
          ]
        }
      ],
      "source": [
        "# Usage with your existing model and tokenizer\n",
        "if __name__ == \"__main__\":\n",
        "    # Assuming your model and tokenizer are already loaded\n",
        "    print(\"Generating DPO training dataset...\")\n",
        "\n",
        "    # Generate training dataset\n",
        "    training_data = generate_dpo_dataset(model, tokenizer, num_examples=50)  # Start small\n",
        "\n",
        "    # Save the data\n",
        "    with open('flan_t5_dpo_training.json', 'w') as f:\n",
        "        json.dump(training_data, f, indent=2)\n",
        "\n",
        "    print(f\"Saved {len(training_data)} training examples to 'flan_t5_dpo_training.json'\")\n",
        "\n",
        "    # Show sample\n",
        "    if training_data:\n",
        "        print(\"\\nSample training example:\")\n",
        "        sample = training_data[0]\n",
        "        print(f\"Question: {sample['original_question']}\")\n",
        "        print(f\"Chosen: {sample['chosen'][:200]}...\")\n",
        "        print(f\"Rejected: {sample['rejected'][:200]}...\")\n",
        "        print(f\"Reasoning: {sample['judgment_reasoning']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Eo82tv7KAT77"
      },
      "outputs": [],
      "source": [
        "class LegalT5DPOTrainer:\n",
        "    def __init__(self, model_name: str = \"google/flan-t5-small\"):\n",
        "        self.model_name = model_name\n",
        "        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "        # Set pad token if not already set\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        print(f\"Loaded model: {model_name}\")\n",
        "        print(f\"Model parameters: {self.model.num_parameters():,}\")\n",
        "\n",
        "    def prepare_dpo_dataset(self, training_data_file: str):\n",
        "        \"\"\"Load and prepare DPO training dataset\"\"\"\n",
        "\n",
        "        with open(training_data_file, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Prepare data for DPO format - simplified for CPU training\n",
        "        dataset_dict = {\n",
        "            'prompt': [item['question'] for item in data],\n",
        "            'chosen': [item['chosen'] for item in data],\n",
        "            'rejected': [item['rejected'] for item in data]\n",
        "        }\n",
        "\n",
        "        dataset = Dataset.from_dict(dataset_dict)\n",
        "        print(f\"Prepared dataset with {len(dataset)} examples\")\n",
        "        return dataset\n",
        "\n",
        "    def train_with_dpo(self, training_data_file: str, output_dir: str = \"./flan-t5-legal-dpo\"):\n",
        "        \"\"\"Train the model using DPO (simplified for compatibility)\"\"\"\n",
        "\n",
        "        try:\n",
        "            from trl import DPOTrainer, DPOConfig\n",
        "        except ImportError:\n",
        "            raise Exception(\"DPO requires 'trl' library: pip install trl\")\n",
        "\n",
        "        # Prepare dataset\n",
        "        train_dataset = self.prepare_dpo_dataset(training_data_file)\n",
        "\n",
        "        # CPU-friendly DPO Training configuration\n",
        "        training_args = DPOConfig(\n",
        "            output_dir=output_dir,\n",
        "            num_train_epochs=2,\n",
        "            per_device_train_batch_size=1,\n",
        "            gradient_accumulation_steps=4,\n",
        "            warmup_steps=20,\n",
        "            logging_steps=5,\n",
        "            save_steps=100,\n",
        "            learning_rate=1e-5,\n",
        "            fp16=False,\n",
        "            bf16=False,\n",
        "            remove_unused_columns=False,\n",
        "            report_to=None,\n",
        "            dataloader_pin_memory=False,\n",
        "            dataloader_num_workers=0,\n",
        "        )\n",
        "\n",
        "        print(\"Initializing DPO trainer for CPU training...\")\n",
        "\n",
        "        # Try minimal DPOTrainer initialization\n",
        "        try:\n",
        "            dpo_trainer = DPOTrainer(\n",
        "                model=self.model,\n",
        "                args=training_args,\n",
        "                train_dataset=train_dataset,\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"DPOTrainer initialization failed: {e}\")\n",
        "            # Try with different parameter combinations\n",
        "            try:\n",
        "                dpo_trainer = DPOTrainer(\n",
        "                    self.model,\n",
        "                    training_args,\n",
        "                    train_dataset,\n",
        "                )\n",
        "            except Exception as e2:\n",
        "                print(f\"Alternative DPOTrainer init failed: {e2}\")\n",
        "                raise Exception(\"DPO initialization failed - falling back to standard fine-tuning\")\n",
        "\n",
        "        print(\"Starting DPO training on CPU (this may take a while)...\")\n",
        "        dpo_trainer.train()\n",
        "\n",
        "        # Save the fine-tuned model\n",
        "        dpo_trainer.save_model(output_dir)\n",
        "        self.tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "        print(f\"DPO training complete! Model saved to {output_dir}\")\n",
        "        return output_dir\n",
        "\n",
        "    def train_with_standard_finetuning(self, training_data_file: str, output_dir: str = \"./flan-t5-legal-ft\"):\n",
        "        \"\"\"Alternative: Standard fine-tuning approach (if DPO doesn't work)\"\"\"\n",
        "\n",
        "        with open(training_data_file, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Prepare data for standard fine-tuning (using only chosen responses)\n",
        "        train_data = []\n",
        "        for item in data:\n",
        "            train_data.append({\n",
        "                'input_text': item['question'],\n",
        "                'target_text': item['chosen']\n",
        "            })\n",
        "\n",
        "        # Create dataset\n",
        "        def preprocess_function(examples):\n",
        "            inputs = [ex['input_text'] for ex in examples]\n",
        "            targets = [ex['target_text'] for ex in examples]\n",
        "\n",
        "            model_inputs = self.tokenizer(\n",
        "                inputs,\n",
        "                max_length=512,\n",
        "                truncation=True,\n",
        "                padding='max_length'\n",
        "            )\n",
        "\n",
        "            labels = self.tokenizer(\n",
        "                targets,\n",
        "                max_length=256,\n",
        "                truncation=True,\n",
        "                padding='max_length'\n",
        "            )\n",
        "\n",
        "            model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "            return model_inputs\n",
        "\n",
        "        dataset = Dataset.from_list(train_data)\n",
        "        tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "        # Training arguments\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=output_dir,\n",
        "            num_train_epochs=3,\n",
        "            per_device_train_batch_size=4,\n",
        "            gradient_accumulation_steps=2,\n",
        "            warmup_steps=100,\n",
        "            logging_steps=10,\n",
        "            save_steps=500,\n",
        "            learning_rate=3e-4,\n",
        "            fp16=torch.cuda.is_available(),\n",
        "            report_to=None,\n",
        "        )\n",
        "\n",
        "        # Data collator\n",
        "        data_collator = DataCollatorForSeq2Seq(\n",
        "            tokenizer=self.tokenizer,\n",
        "            model=self.model,\n",
        "            padding=True\n",
        "        )\n",
        "\n",
        "        # Trainer\n",
        "        trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=training_args,\n",
        "            train_dataset=tokenized_dataset,\n",
        "            data_collator=data_collator,\n",
        "        )\n",
        "\n",
        "        print(\"Starting standard fine-tuning...\")\n",
        "        trainer.train()\n",
        "\n",
        "        # Save model\n",
        "        trainer.save_model(output_dir)\n",
        "        self.tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "        print(f\"Fine-tuning complete! Model saved to {output_dir}\")\n",
        "        return output_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Yy-wAK5tAWaK"
      },
      "outputs": [],
      "source": [
        "def generate_text_with_model(model, tokenizer, prompt, max_length=200):\n",
        "    \"\"\"Generate text using a specific model\"\"\"\n",
        "    formatted_prompt = f\"Answer this legal question: {prompt}\"\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        formatted_prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs['input_ids'],\n",
        "            attention_mask=inputs['attention_mask'],\n",
        "            max_length=max_length,\n",
        "            num_return_sequences=1,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            pad_token_id=tokenizer.pad_token_id\n",
        "        )\n",
        "\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return generated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Aki3yZcsAYt7"
      },
      "outputs": [],
      "source": [
        "def evaluate_before_after(original_model_name: str, finetuned_model_path: str, test_questions: list):\n",
        "    \"\"\"Compare original and fine-tuned model responses\"\"\"\n",
        "\n",
        "    print(\"Loading models for comparison...\")\n",
        "\n",
        "    # Load original model\n",
        "    original_tokenizer = T5Tokenizer.from_pretrained(original_model_name)\n",
        "    original_model = T5ForConditionalGeneration.from_pretrained(original_model_name)\n",
        "\n",
        "    # Load fine-tuned model\n",
        "    finetuned_tokenizer = T5Tokenizer.from_pretrained(finetuned_model_path)\n",
        "    finetuned_model = T5ForConditionalGeneration.from_pretrained(finetuned_model_path)\n",
        "\n",
        "    print(\"Generating responses...\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for i, question in enumerate(test_questions, 1):\n",
        "        print(f\"Processing question {i}/{len(test_questions)}\")\n",
        "\n",
        "        # Generate responses\n",
        "        original_response = generate_text_with_model(original_model, original_tokenizer, question)\n",
        "        finetuned_response = generate_text_with_model(finetuned_model, finetuned_tokenizer, question)\n",
        "\n",
        "        results.append({\n",
        "            'question': question,\n",
        "            'original_response': original_response,\n",
        "            'finetuned_response': finetuned_response\n",
        "        })\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "RQs88eyEAdA0"
      },
      "outputs": [],
      "source": [
        "def save_comparison_results(results: list, filename: str = \"before_after_comparison.json\"):\n",
        "    \"\"\"Save comparison results to file\"\"\"\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "    # Also create a readable text version\n",
        "    text_filename = filename.replace('.json', '.txt')\n",
        "    with open(text_filename, 'w') as f:\n",
        "        f.write(\"FLAN-T5 Legal Fine-tuning: Before vs After Comparison\\n\")\n",
        "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
        "\n",
        "        for i, result in enumerate(results, 1):\n",
        "            f.write(f\"QUESTION {i}:\\n{result['question']}\\n\\n\")\n",
        "            f.write(f\"ORIGINAL MODEL:\\n{result['original_response']}\\n\\n\")\n",
        "            f.write(f\"FINE-TUNED MODEL:\\n{result['finetuned_response']}\\n\\n\")\n",
        "            f.write(\"-\" * 60 + \"\\n\\n\")\n",
        "\n",
        "    print(f\"Results saved to {filename} and {text_filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9ca559bdfe284788aaecd0b8fdf7c53a",
            "8a5591e89df1415d9b5d5fc34d9a157d",
            "184a14ae855e40beb94b2970c44909c1",
            "7b2153ce73124e219b0139ed738fbbf3",
            "8d58acb61b334c70ad0a3ce2bf25e49e",
            "11e9491c5364466f99f9a3f55919477e",
            "996d6a657e804b2c8b05c89eda92f454",
            "bd292a779c1343a288f40167891e27ca",
            "0285543a82ea48cb913e7afad51c8eee",
            "2ba806cb5a674b40bb708c66552bbeb6",
            "de99ead0895745b4b6cbaa3bbe04b3d4",
            "16b2f72ea9db4e46b4791aada394049f",
            "934df53f71f44ab6bfdb6bab16619f9b",
            "e95cdfebfe7446818f32dde17952be7d",
            "8680475944df4579a729e312c13caf38",
            "af802d9b35a24c1ca57c2aa905cc4b21",
            "7a0867b582d64dc3a3f5eb657d852ad3",
            "36bcaeeac9af412eb55e3747703ae15c",
            "5e76ed46b0dc40bfacd1ad0d453b74be",
            "d373ae3c53b24bf58c816de911ac683f",
            "a193857a9b324a628ce3f2bb969a4dba",
            "cec924e20987484b867f34fe5fdabc1c",
            "288c8b9e93434c54a9394e4abf9d99cc",
            "43bcd5295a644c4893e786ff7dd4cec5",
            "c583c51361d6463e9a9521fccdbdc68d",
            "249b833825cc447bb45e65d7eae6c17e",
            "49dc42cf301e4f39807d3cb6ecd8b058",
            "1da6d27c32f248ec8f0d4625f1171e73",
            "51f3b4cb75d743afabafcf34eaa3f15a",
            "98bc6bc1b8344e57b38f28aaa2594af8",
            "ef9271ad710345dbac562781fa4f5f48",
            "21374d488d6a4089a960a0ad4c92f075",
            "aa305593d0324bbb93ebaafed86ba35c"
          ]
        },
        "id": "VHFhFOnVAdra",
        "outputId": "46a238c0-1499-4fcb-ef6a-91786d360a8d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded model: google/flan-t5-small\n",
            "Model parameters: 76,961,152\n",
            "Training data found. Starting training...\n",
            "Prepared dataset with 11 examples\n",
            "Initializing DPO trainer for CPU training...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ca559bdfe284788aaecd0b8fdf7c53a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting prompt in train dataset:   0%|          | 0/11 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16b2f72ea9db4e46b4791aada394049f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying chat template to train dataset:   0%|          | 0/11 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "288c8b9e93434c54a9394e4abf9d99cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/11 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting DPO training on CPU (this may take a while)...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6/6 00:23, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.094300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DPO training complete! Model saved to ./flan-t5-legal-dpo\n",
            "\n",
            "================================================================================\n",
            "LOADING MODELS FOR COMPARISON\n",
            "================================================================================\n",
            "Loading original FLAN-T5 model...\n",
            "Loading fine-tuned model...\n",
            "\n",
            "================================================================================\n",
            "BEFORE vs AFTER TRAINING COMPARISON\n",
            "================================================================================\n",
            "\n",
            "==================== QUESTION 1 ====================\n",
            "Q: What is the legal standard for establishing proximate cause in tort law?\n",
            "ORIGINAL MODEL: Prohibition of a claim\n",
            "FINE-TUNED MODEL: proximate cause\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "==================== QUESTION 2 ====================\n",
            "Q: Explain the difference between a warranty deed and a quitclaim deed in real estate transactions.\n",
            "ORIGINAL MODEL: a warranty deed is a separate claim from a reclaim on the property.\n",
            "FINE-TUNED MODEL: Preventive compensation is typically the same as a loss of income or the loss of money, including the loss of a house in a mortgage or a financial gain.\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "==================== QUESTION 3 ====================\n",
            "Q: What constitutes a material breach of contract versus a minor breach?\n",
            "ORIGINAL MODEL: contract-only agreement\n",
            "FINE-TUNED MODEL: contract\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "==================== QUESTION 4 ====================\n",
            "Q: Define the elements required to prove negligence in a personal injury case.\n",
            "ORIGINAL MODEL: The elements in the case are the following:\n",
            "FINE-TUNED MODEL: A person may have to be taken to the hospital to be liable for his or her injuries, and if this means he or she is not injured.\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "==================== QUESTION 5 ====================\n",
            "Q: What is the doctrine of respondeat superior and when does it apply?\n",
            "ORIGINAL MODEL: \n",
            "FINE-TUNED MODEL: v.\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "==================== QUESTION 6 ====================\n",
            "Q: Explain the difference between joint tenancy and tenancy in common.\n",
            "ORIGINAL MODEL: Joint tenancy is a condition where one a child is born and has a tendency to have a strong sense of humor.\n",
            "FINE-TUNED MODEL: Joint tenancy is the tenancy that occurs as the body carries out a series of functions, and a part of the body that moves forward.\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "==================== QUESTION 7 ====================\n",
            "Q: What are the requirements for a valid will under most state laws?\n",
            "ORIGINAL MODEL: iracial disapproval\n",
            "FINE-TUNED MODEL: a valid will\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "==================== QUESTION 8 ====================\n",
            "Q: Define the burden of proof in criminal cases versus civil cases.\n",
            "ORIGINAL MODEL: a felony is a criminal offense that is considered to have been a felony.\n",
            "FINE-TUNED MODEL: felony felony felony\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "==================== QUESTION 9 ====================\n",
            "Q: What is the statute of limitations and how does it vary by type of legal claim?\n",
            "ORIGINAL MODEL: The maximum legal penalty for the use of a particular property is 1.\n",
            "FINE-TUNED MODEL: Statute of limitations\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "==================== QUESTION 10 ====================\n",
            "Q: Explain the concept of adverse possession and its legal requirements.\n",
            "ORIGINAL MODEL: This is the simplest of the following.\n",
            "FINE-TUNED MODEL: Legal definitions of adverse possession include the use of a drug to a drug marketed as a drug, the use of a drug for a drug, and the use of an alcohol.\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "==================== QUESTION 11 ====================\n",
            "Q: What constitutes defamation and what defenses are available?\n",
            "ORIGINAL MODEL: judicial decision\n",
            "FINE-TUNED MODEL: federal\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "==================== QUESTION 12 ====================\n",
            "Q: Define the difference between an easement and a license in property law.\n",
            "ORIGINAL MODEL: a ci-enablement or a contract\n",
            "FINE-TUNED MODEL: delinquents\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "==================== QUESTION 13 ====================\n",
            "Q: What are the elements of a valid contract formation?\n",
            "ORIGINAL MODEL: contract formation\n",
            "FINE-TUNED MODEL: contract\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "==================== QUESTION 14 ====================\n",
            "Q: Explain the doctrine of comparative negligence versus contributory negligence.\n",
            "ORIGINAL MODEL: Contributions can be deducted from all liability claims.\n",
            "FINE-TUNED MODEL: This doctrine refers to the \"common negligence\" principle of which, in a sense, negligence is a form of negligence.\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "==================== QUESTION 15 ====================\n",
            "Q: What is the legal concept of standing to sue in federal court?\n",
            "ORIGINAL MODEL: federal senate\n",
            "FINE-TUNED MODEL: a court of law\n",
            "\n",
            "====================================================================================================\n",
            "\n",
            "Training and evaluation complete!\n",
            "You can see the side-by-side comparison above to evaluate improvements.\n"
          ]
        }
      ],
      "source": [
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Your test questions\n",
        "    test_questions = [\n",
        "        \"What is the legal standard for establishing proximate cause in tort law?\",\n",
        "        \"Explain the difference between a warranty deed and a quitclaim deed in real estate transactions.\",\n",
        "        \"What constitutes a material breach of contract versus a minor breach?\",\n",
        "        \"Define the elements required to prove negligence in a personal injury case.\",\n",
        "        \"What is the doctrine of respondeat superior and when does it apply?\",\n",
        "        \"Explain the difference between joint tenancy and tenancy in common.\",\n",
        "        \"What are the requirements for a valid will under most state laws?\",\n",
        "        \"Define the burden of proof in criminal cases versus civil cases.\",\n",
        "        \"What is the statute of limitations and how does it vary by type of legal claim?\",\n",
        "        \"Explain the concept of adverse possession and its legal requirements.\",\n",
        "        \"What constitutes defamation and what defenses are available?\",\n",
        "        \"Define the difference between an easement and a license in property law.\",\n",
        "        \"What are the elements of a valid contract formation?\",\n",
        "        \"Explain the doctrine of comparative negligence versus contributory negligence.\",\n",
        "        \"What is the legal concept of standing to sue in federal court?\"\n",
        "    ]\n",
        "\n",
        "    # Step 1: Initialize trainer\n",
        "    trainer = LegalT5DPOTrainer(\"google/flan-t5-small\")\n",
        "\n",
        "    # Step 2: Train the model (make sure you have generated training data first)\n",
        "    training_data_file = \"flan_t5_dpo_training.json\"  # From the previous script\n",
        "\n",
        "    if os.path.exists(training_data_file):\n",
        "        print(\"Training data found. Starting training...\")\n",
        "\n",
        "        try:\n",
        "            # Try DPO training first (with better error handling)\n",
        "            finetuned_model_path = trainer.train_with_dpo(training_data_file)\n",
        "        except Exception as e:\n",
        "            print(f\"DPO training failed: {e}\")\n",
        "            print(\"Falling back to standard fine-tuning (which works just as well for your portfolio)...\")\n",
        "            finetuned_model_path = trainer.train_with_standard_finetuning(training_data_file)\n",
        "\n",
        "        # Step 3: Load both models for comparison\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"LOADING MODELS FOR COMPARISON\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Load original model\n",
        "        print(\"Loading original FLAN-T5 model...\")\n",
        "        original_tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
        "        original_model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\")\n",
        "\n",
        "        # Load fine-tuned model\n",
        "        print(\"Loading fine-tuned model...\")\n",
        "        finetuned_tokenizer = T5Tokenizer.from_pretrained(finetuned_model_path)\n",
        "        finetuned_model = T5ForConditionalGeneration.from_pretrained(finetuned_model_path)\n",
        "\n",
        "        # Step 4: Generate and display side-by-side comparison\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"BEFORE vs AFTER TRAINING COMPARISON\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        for i, question in enumerate(test_questions, 1):\n",
        "            print(f\"\\n{'='*20} QUESTION {i} {'='*20}\")\n",
        "            print(f\"Q: {question}\")\n",
        "\n",
        "            # Generate response with original model\n",
        "            original_response = generate_text_with_model(original_model, original_tokenizer, question, max_length=200)\n",
        "            print(f\"ORIGINAL MODEL: {original_response}\")\n",
        "\n",
        "\n",
        "            # Generate response with fine-tuned model\n",
        "            finetuned_response = generate_text_with_model(finetuned_model, finetuned_tokenizer, question, max_length=200)\n",
        "            print(f\"FINE-TUNED MODEL: {finetuned_response}\")\n",
        "\n",
        "            print(\"\\n\" + \"=\"*100)\n",
        "\n",
        "        print(\"\\nTraining and evaluation complete!\")\n",
        "        print(\"You can see the side-by-side comparison above to evaluate improvements.\")\n",
        "\n",
        "    else:\n",
        "        print(f\"Training data file '{training_data_file}' not found.\")\n",
        "        print(\"Please run the training data generation script first.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0285543a82ea48cb913e7afad51c8eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11e9491c5364466f99f9a3f55919477e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16b2f72ea9db4e46b4791aada394049f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_934df53f71f44ab6bfdb6bab16619f9b",
              "IPY_MODEL_e95cdfebfe7446818f32dde17952be7d",
              "IPY_MODEL_8680475944df4579a729e312c13caf38"
            ],
            "layout": "IPY_MODEL_af802d9b35a24c1ca57c2aa905cc4b21"
          }
        },
        "184a14ae855e40beb94b2970c44909c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd292a779c1343a288f40167891e27ca",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0285543a82ea48cb913e7afad51c8eee",
            "value": 11
          }
        },
        "1da6d27c32f248ec8f0d4625f1171e73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21374d488d6a4089a960a0ad4c92f075": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "249b833825cc447bb45e65d7eae6c17e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21374d488d6a4089a960a0ad4c92f075",
            "placeholder": "​",
            "style": "IPY_MODEL_aa305593d0324bbb93ebaafed86ba35c",
            "value": " 11/11 [00:00&lt;00:00, 278.30 examples/s]"
          }
        },
        "288c8b9e93434c54a9394e4abf9d99cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43bcd5295a644c4893e786ff7dd4cec5",
              "IPY_MODEL_c583c51361d6463e9a9521fccdbdc68d",
              "IPY_MODEL_249b833825cc447bb45e65d7eae6c17e"
            ],
            "layout": "IPY_MODEL_49dc42cf301e4f39807d3cb6ecd8b058"
          }
        },
        "2ba806cb5a674b40bb708c66552bbeb6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36bcaeeac9af412eb55e3747703ae15c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43bcd5295a644c4893e786ff7dd4cec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1da6d27c32f248ec8f0d4625f1171e73",
            "placeholder": "​",
            "style": "IPY_MODEL_51f3b4cb75d743afabafcf34eaa3f15a",
            "value": "Tokenizing train dataset: 100%"
          }
        },
        "49dc42cf301e4f39807d3cb6ecd8b058": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51f3b4cb75d743afabafcf34eaa3f15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e76ed46b0dc40bfacd1ad0d453b74be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a0867b582d64dc3a3f5eb657d852ad3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b2153ce73124e219b0139ed738fbbf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ba806cb5a674b40bb708c66552bbeb6",
            "placeholder": "​",
            "style": "IPY_MODEL_de99ead0895745b4b6cbaa3bbe04b3d4",
            "value": " 11/11 [00:00&lt;00:00, 520.30 examples/s]"
          }
        },
        "8680475944df4579a729e312c13caf38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a193857a9b324a628ce3f2bb969a4dba",
            "placeholder": "​",
            "style": "IPY_MODEL_cec924e20987484b867f34fe5fdabc1c",
            "value": " 11/11 [00:00&lt;00:00, 463.96 examples/s]"
          }
        },
        "8a5591e89df1415d9b5d5fc34d9a157d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11e9491c5364466f99f9a3f55919477e",
            "placeholder": "​",
            "style": "IPY_MODEL_996d6a657e804b2c8b05c89eda92f454",
            "value": "Extracting prompt in train dataset: 100%"
          }
        },
        "8d58acb61b334c70ad0a3ce2bf25e49e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "934df53f71f44ab6bfdb6bab16619f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a0867b582d64dc3a3f5eb657d852ad3",
            "placeholder": "​",
            "style": "IPY_MODEL_36bcaeeac9af412eb55e3747703ae15c",
            "value": "Applying chat template to train dataset: 100%"
          }
        },
        "98bc6bc1b8344e57b38f28aaa2594af8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "996d6a657e804b2c8b05c89eda92f454": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ca559bdfe284788aaecd0b8fdf7c53a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a5591e89df1415d9b5d5fc34d9a157d",
              "IPY_MODEL_184a14ae855e40beb94b2970c44909c1",
              "IPY_MODEL_7b2153ce73124e219b0139ed738fbbf3"
            ],
            "layout": "IPY_MODEL_8d58acb61b334c70ad0a3ce2bf25e49e"
          }
        },
        "a193857a9b324a628ce3f2bb969a4dba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa305593d0324bbb93ebaafed86ba35c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af802d9b35a24c1ca57c2aa905cc4b21": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd292a779c1343a288f40167891e27ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c583c51361d6463e9a9521fccdbdc68d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98bc6bc1b8344e57b38f28aaa2594af8",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef9271ad710345dbac562781fa4f5f48",
            "value": 11
          }
        },
        "cec924e20987484b867f34fe5fdabc1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d373ae3c53b24bf58c816de911ac683f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de99ead0895745b4b6cbaa3bbe04b3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e95cdfebfe7446818f32dde17952be7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e76ed46b0dc40bfacd1ad0d453b74be",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d373ae3c53b24bf58c816de911ac683f",
            "value": 11
          }
        },
        "ef9271ad710345dbac562781fa4f5f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
